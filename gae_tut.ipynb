{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import train_test_split_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bargav/anaconda3/envs/clean_ml/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid(\"\\..\", \"CiteSeer\", transform=T.NormalizeFeatures())\n",
    "dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.data\n",
    "data.train_mask = data.val_mask = data.test_mask = None\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 628,  158,  486,  ..., 2820, 1643,   33])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bargav/anaconda3/envs/clean_ml/lib/python3.11/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "data = train_test_split_edges(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3327, 3703], y=[3327], val_pos_edge_index=[2, 227], test_pos_edge_index=[2, 455], train_pos_edge_index=[2, 7740], train_neg_adj_mask=[3327, 3327], val_neg_edge_index=[2, 227], test_neg_edge_index=[2, 455])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.gconv1 = GCNConv(in_channels, hidden_dim, cached=True) # Cached for transductive learning\n",
    "        self.gconv2 = GCNConv(hidden_dim, out_channels, cached=True)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gconv1(x, edge_index).relu()\n",
    "        return self.gconv2(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3703"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = data.x.shape[1]\n",
    "out_channels = 2\n",
    "hidden_dim = 24\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "encoder = GCNEncoder(in_channels,hidden_dim, out_channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load available Device \n",
    "\n",
    "device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "mps_device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Graph AutoEncoder\n",
    "\n",
    "from torch_geometric.nn import GAE\n",
    "\n",
    "model = GAE(encoder)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.x.to(device)\n",
    "\n",
    "train_pos_edge_indices = data.train_pos_edge_index.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr  = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tensorboard\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter(f'runs/GAE_experiment_{out_channels}d_{num_epochs}epochs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(X, train_pos_edge_indices)\n",
    "    loss = model.recon_loss(z, train_pos_edge_indices)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "def test(pos_edge_indices, neg_edge_indices):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(X, train_pos_edge_indices)\n",
    "        \n",
    "    return model.test(z, pos_edge_indices, neg_edge_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000, AUC: 0.625, Average Precision: 0.635\n",
      "Epoch 001, AUC: 0.640, Average Precision: 0.664\n",
      "Epoch 002, AUC: 0.649, Average Precision: 0.681\n",
      "Epoch 003, AUC: 0.655, Average Precision: 0.694\n",
      "Epoch 004, AUC: 0.662, Average Precision: 0.704\n",
      "Epoch 005, AUC: 0.668, Average Precision: 0.712\n",
      "Epoch 006, AUC: 0.678, Average Precision: 0.723\n",
      "Epoch 007, AUC: 0.691, Average Precision: 0.736\n",
      "Epoch 008, AUC: 0.707, Average Precision: 0.749\n",
      "Epoch 009, AUC: 0.726, Average Precision: 0.764\n",
      "Epoch 010, AUC: 0.747, Average Precision: 0.779\n",
      "Epoch 011, AUC: 0.769, Average Precision: 0.795\n",
      "Epoch 012, AUC: 0.788, Average Precision: 0.808\n",
      "Epoch 013, AUC: 0.802, Average Precision: 0.819\n",
      "Epoch 014, AUC: 0.811, Average Precision: 0.826\n",
      "Epoch 015, AUC: 0.818, Average Precision: 0.832\n",
      "Epoch 016, AUC: 0.823, Average Precision: 0.835\n",
      "Epoch 017, AUC: 0.826, Average Precision: 0.838\n",
      "Epoch 018, AUC: 0.829, Average Precision: 0.840\n",
      "Epoch 019, AUC: 0.831, Average Precision: 0.841\n",
      "Epoch 020, AUC: 0.833, Average Precision: 0.842\n",
      "Epoch 021, AUC: 0.835, Average Precision: 0.844\n",
      "Epoch 022, AUC: 0.836, Average Precision: 0.845\n",
      "Epoch 023, AUC: 0.838, Average Precision: 0.847\n",
      "Epoch 024, AUC: 0.839, Average Precision: 0.848\n",
      "Epoch 025, AUC: 0.840, Average Precision: 0.849\n",
      "Epoch 026, AUC: 0.841, Average Precision: 0.850\n",
      "Epoch 027, AUC: 0.841, Average Precision: 0.850\n",
      "Epoch 028, AUC: 0.842, Average Precision: 0.851\n",
      "Epoch 029, AUC: 0.843, Average Precision: 0.852\n",
      "Epoch 030, AUC: 0.842, Average Precision: 0.852\n",
      "Epoch 031, AUC: 0.842, Average Precision: 0.852\n",
      "Epoch 032, AUC: 0.842, Average Precision: 0.851\n",
      "Epoch 033, AUC: 0.841, Average Precision: 0.851\n",
      "Epoch 034, AUC: 0.840, Average Precision: 0.850\n",
      "Epoch 035, AUC: 0.839, Average Precision: 0.849\n",
      "Epoch 036, AUC: 0.837, Average Precision: 0.848\n",
      "Epoch 037, AUC: 0.836, Average Precision: 0.847\n",
      "Epoch 038, AUC: 0.835, Average Precision: 0.845\n",
      "Epoch 039, AUC: 0.833, Average Precision: 0.844\n",
      "Epoch 040, AUC: 0.832, Average Precision: 0.843\n",
      "Epoch 041, AUC: 0.831, Average Precision: 0.842\n",
      "Epoch 042, AUC: 0.831, Average Precision: 0.841\n",
      "Epoch 043, AUC: 0.830, Average Precision: 0.841\n",
      "Epoch 044, AUC: 0.829, Average Precision: 0.840\n",
      "Epoch 045, AUC: 0.829, Average Precision: 0.840\n",
      "Epoch 046, AUC: 0.828, Average Precision: 0.839\n",
      "Epoch 047, AUC: 0.828, Average Precision: 0.840\n",
      "Epoch 048, AUC: 0.828, Average Precision: 0.839\n",
      "Epoch 049, AUC: 0.828, Average Precision: 0.840\n",
      "Epoch 050, AUC: 0.828, Average Precision: 0.840\n",
      "Epoch 051, AUC: 0.828, Average Precision: 0.840\n",
      "Epoch 052, AUC: 0.828, Average Precision: 0.840\n",
      "Epoch 053, AUC: 0.828, Average Precision: 0.840\n",
      "Epoch 054, AUC: 0.828, Average Precision: 0.839\n",
      "Epoch 055, AUC: 0.827, Average Precision: 0.839\n",
      "Epoch 056, AUC: 0.827, Average Precision: 0.838\n",
      "Epoch 057, AUC: 0.827, Average Precision: 0.838\n",
      "Epoch 058, AUC: 0.827, Average Precision: 0.838\n",
      "Epoch 059, AUC: 0.826, Average Precision: 0.838\n",
      "Epoch 060, AUC: 0.826, Average Precision: 0.837\n",
      "Epoch 061, AUC: 0.826, Average Precision: 0.837\n",
      "Epoch 062, AUC: 0.825, Average Precision: 0.837\n",
      "Epoch 063, AUC: 0.825, Average Precision: 0.837\n",
      "Epoch 064, AUC: 0.824, Average Precision: 0.836\n",
      "Epoch 065, AUC: 0.824, Average Precision: 0.836\n",
      "Epoch 066, AUC: 0.824, Average Precision: 0.835\n",
      "Epoch 067, AUC: 0.823, Average Precision: 0.835\n",
      "Epoch 068, AUC: 0.823, Average Precision: 0.835\n",
      "Epoch 069, AUC: 0.823, Average Precision: 0.834\n",
      "Epoch 070, AUC: 0.822, Average Precision: 0.834\n",
      "Epoch 071, AUC: 0.822, Average Precision: 0.834\n",
      "Epoch 072, AUC: 0.821, Average Precision: 0.834\n",
      "Epoch 073, AUC: 0.821, Average Precision: 0.833\n",
      "Epoch 074, AUC: 0.820, Average Precision: 0.833\n",
      "Epoch 075, AUC: 0.820, Average Precision: 0.832\n",
      "Epoch 076, AUC: 0.819, Average Precision: 0.832\n",
      "Epoch 077, AUC: 0.819, Average Precision: 0.831\n",
      "Epoch 078, AUC: 0.819, Average Precision: 0.831\n",
      "Epoch 079, AUC: 0.819, Average Precision: 0.831\n",
      "Epoch 080, AUC: 0.819, Average Precision: 0.831\n",
      "Epoch 081, AUC: 0.818, Average Precision: 0.830\n",
      "Epoch 082, AUC: 0.818, Average Precision: 0.830\n",
      "Epoch 083, AUC: 0.817, Average Precision: 0.830\n",
      "Epoch 084, AUC: 0.817, Average Precision: 0.830\n",
      "Epoch 085, AUC: 0.817, Average Precision: 0.829\n",
      "Epoch 086, AUC: 0.817, Average Precision: 0.829\n",
      "Epoch 087, AUC: 0.817, Average Precision: 0.829\n",
      "Epoch 088, AUC: 0.817, Average Precision: 0.829\n",
      "Epoch 089, AUC: 0.817, Average Precision: 0.829\n",
      "Epoch 090, AUC: 0.816, Average Precision: 0.829\n",
      "Epoch 091, AUC: 0.816, Average Precision: 0.829\n",
      "Epoch 092, AUC: 0.815, Average Precision: 0.828\n",
      "Epoch 093, AUC: 0.815, Average Precision: 0.828\n",
      "Epoch 094, AUC: 0.815, Average Precision: 0.828\n",
      "Epoch 095, AUC: 0.815, Average Precision: 0.828\n",
      "Epoch 096, AUC: 0.814, Average Precision: 0.827\n",
      "Epoch 097, AUC: 0.814, Average Precision: 0.827\n",
      "Epoch 098, AUC: 0.814, Average Precision: 0.827\n",
      "Epoch 099, AUC: 0.814, Average Precision: 0.827\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    loss = train()\n",
    "\n",
    "    auc, avg_precision = test(data.test_pos_edge_index, data.test_neg_edge_index)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d}, AUC: {auc:.3f}, Average Precision: {avg_precision:.3f}\")\n",
    "\n",
    "    writer.add_scalar('auc train', auc, epoch)\n",
    "    writer.add_scalar('average precision', avg_precision, epoch )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3539,  0.4916],\n",
      "        [ 1.3507,  0.1492],\n",
      "        [-0.9123,  0.0574],\n",
      "        ...,\n",
      "        [ 0.8074,  1.0721],\n",
      "        [-0.8290, -0.1964],\n",
      "        [-0.6791,  0.7380]], device='mps:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "Z = model.encode(X, train_pos_edge_indices)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
